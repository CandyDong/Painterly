{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import torch\n",
    "import numpy as np\n",
    "import argparse\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from DRL.actor import *\n",
    "from Renderer.stroke_gen import *\n",
    "from Renderer.model import *\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "width = 128\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Arg():\n",
    "    def __init__(self):\n",
    "        self.max_step=20\n",
    "        self.actor='./model/actor_oil.pkl'\n",
    "        self.renderer='./model/renderer_oil.pkl'\n",
    "        self.img='../image/1.png'\n",
    "        self.imgid=0\n",
    "        self.divide=8\n",
    "\n",
    "args = Arg()\n",
    "\n",
    "canvas_cnt = args.divide * args.divide\n",
    "T = torch.ones([1, 1, width, width], dtype=torch.float32).to(device)\n",
    "img = cv2.imread(args.img, cv2.IMREAD_COLOR)\n",
    "origin_shape = (img.shape[1], img.shape[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "coord = torch.zeros([1, 2, width, width])\n",
    "for i in range(width):\n",
    "    for j in range(width):\n",
    "        coord[0, 0, i, j] = i / (width - 1.)\n",
    "        coord[0, 1, i, j] = j / (width - 1.)\n",
    "coord = coord.to(device) # Coordconv\n",
    "\n",
    "Decoder = FCN()\n",
    "Decoder.load_state_dict(torch.load(args.renderer))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode(x, canvas): # b * (10 + 3)\n",
    "    x = x.view(-1, 10 + 3)\n",
    "    stroke = 1 - Decoder(x[:, :10])\n",
    "    stroke = stroke.view(-1, width, width, 1)\n",
    "    color_stroke = stroke * x[:, -3:].view(-1, 1, 1, 3)\n",
    "    stroke = stroke.permute(0, 3, 1, 2)\n",
    "    color_stroke = color_stroke.permute(0, 3, 1, 2)\n",
    "    stroke = stroke.view(-1, 5, 1, width, width)\n",
    "    color_stroke = color_stroke.view(-1, 5, 3, width, width)\n",
    "    res = []\n",
    "    for i in range(5):\n",
    "        canvas = canvas * (1 - stroke[:, i]) + color_stroke[:, i]\n",
    "        res.append(canvas)\n",
    "    return canvas, res\n",
    "\n",
    "def small2large(x):\n",
    "    # (d * d, width, width) -> (d * width, d * width)    \n",
    "    x = x.reshape(args.divide, args.divide, width, width, -1)\n",
    "    x = np.transpose(x, (0, 2, 1, 3, 4))\n",
    "    x = x.reshape(args.divide * width, args.divide * width, -1)\n",
    "    return x\n",
    "\n",
    "def large2small(x):\n",
    "    # (d * width, d * width) -> (d * d, width, width)\n",
    "    x = x.reshape(args.divide, width, args.divide, width, 3)\n",
    "    x = np.transpose(x, (0, 2, 1, 3, 4))\n",
    "    x = x.reshape(canvas_cnt, width, width, 3)\n",
    "    return x\n",
    "\n",
    "def smooth(img):\n",
    "    def smooth_pix(img, tx, ty):\n",
    "        if tx == args.divide * width - 1 or ty == args.divide * width - 1 or tx == 0 or ty == 0: \n",
    "            return img\n",
    "        img[tx, ty] = (img[tx, ty] + img[tx + 1, ty] + img[tx, ty + 1] + img[tx - 1, ty] + img[tx, ty - 1] + img[tx + 1, ty - 1] + img[tx - 1, ty + 1] + img[tx - 1, ty - 1] + img[tx + 1, ty + 1]) / 9\n",
    "        return img\n",
    "\n",
    "    for p in range(args.divide):\n",
    "        for q in range(args.divide):\n",
    "            x = p * width\n",
    "            y = q * width\n",
    "#            if p == args.divide - 1 and q == args.divide - 1:\n",
    "#                continue\n",
    "            for k in range(width):\n",
    "                img = smooth_pix(img, x + k, y + width - 1)\n",
    "                if q != args.divide - 1:\n",
    "                    img = smooth_pix(img, x + k, y + width)\n",
    "            for k in range(width):\n",
    "                img = smooth_pix(img, x + width - 1, y + k)\n",
    "                if p != args.divide - 1:\n",
    "                    img = smooth_pix(img, x + width, y + k)\n",
    "    return img\n",
    "\n",
    "def save_img(res, imgid, divide=False):\n",
    "    output = res.detach().cpu().numpy() # d * d, 3, width, width    \n",
    "    output = np.transpose(output, (0, 2, 3, 1))\n",
    "    if divide:\n",
    "        output = small2large(output)\n",
    "        output = smooth(output)\n",
    "    else:\n",
    "        output = output[0]\n",
    "    output = (output * 255).astype('uint8')\n",
    "    output = cv2.resize(output, origin_shape)\n",
    "    cv2.imwrite('output/generated' + str(imgid) + '.png', output)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "canvas step 0, L2Loss = 0.016744021326303482\n",
      "canvas step 1, L2Loss = 0.011997136287391186\n",
      "canvas step 2, L2Loss = 0.011504968628287315\n",
      "canvas step 3, L2Loss = 0.011475464329123497\n",
      "canvas step 4, L2Loss = 0.011578778736293316\n",
      "canvas step 5, L2Loss = 0.011354690417647362\n",
      "canvas step 6, L2Loss = 0.011463972739875317\n",
      "canvas step 7, L2Loss = 0.011338244192302227\n",
      "canvas step 8, L2Loss = 0.01155879721045494\n",
      "canvas step 9, L2Loss = 0.011343485675752163\n",
      "divided canvas step 0, L2Loss = 0.008992730639874935\n",
      "divided canvas step 1, L2Loss = 0.006866709794849157\n",
      "divided canvas step 2, L2Loss = 0.007015632465481758\n",
      "divided canvas step 3, L2Loss = 0.0063891327008605\n",
      "divided canvas step 4, L2Loss = 0.006614653393626213\n",
      "divided canvas step 5, L2Loss = 0.0063345893286168575\n",
      "divided canvas step 6, L2Loss = 0.0064824591390788555\n",
      "divided canvas step 7, L2Loss = 0.006301374174654484\n",
      "divided canvas step 8, L2Loss = 0.00640516635030508\n",
      "divided canvas step 9, L2Loss = 0.006283374037593603\n"
     ]
    }
   ],
   "source": [
    "actor = ResNet(9, 18, 65) # action_bundle = 5, 65 = 5 * 13\n",
    "actor.load_state_dict(torch.load(args.actor))\n",
    "actor = actor.to(device).eval()\n",
    "Decoder = Decoder.to(device).eval()\n",
    "\n",
    "canvas = torch.zeros([1, 3, width, width]).to(device)\n",
    "\n",
    "patch_img = cv2.resize(img, (width * args.divide, width * args.divide))\n",
    "patch_img = large2small(patch_img)\n",
    "patch_img = np.transpose(patch_img, (0, 3, 1, 2))\n",
    "patch_img = torch.tensor(patch_img).to(device).float() / 255.\n",
    "\n",
    "img = cv2.resize(img, (width, width))\n",
    "img = img.reshape(1, width, width, 3)\n",
    "img = np.transpose(img, (0, 3, 1, 2))\n",
    "img = torch.tensor(img).to(device).float() / 255.\n",
    "\n",
    "os.system('mkdir output')\n",
    "\n",
    "with torch.no_grad():\n",
    "    if args.divide != 1:\n",
    "        args.max_step = args.max_step // 2\n",
    "    for i in range(args.max_step):\n",
    "        stepnum = T * i / args.max_step\n",
    "        actions = actor(torch.cat([canvas, img, stepnum, coord], 1))\n",
    "        canvas, res = decode(actions, canvas)\n",
    "        print('canvas step {}, L2Loss = {}'.format(i, ((canvas - img) ** 2).mean()))\n",
    "        for j in range(5):\n",
    "            save_img(res[j], args.imgid)\n",
    "            args.imgid += 1\n",
    "    if args.divide != 1:\n",
    "        canvas = canvas[0].detach().cpu().numpy()\n",
    "        canvas = np.transpose(canvas, (1, 2, 0))    \n",
    "        canvas = cv2.resize(canvas, (width * args.divide, width * args.divide))\n",
    "        canvas = large2small(canvas)\n",
    "        canvas = np.transpose(canvas, (0, 3, 1, 2))\n",
    "        canvas = torch.tensor(canvas).to(device).float()\n",
    "        coord = coord.expand(canvas_cnt, 2, width, width)\n",
    "        T = T.expand(canvas_cnt, 1, width, width)\n",
    "        for i in range(args.max_step):\n",
    "            stepnum = T * i / args.max_step\n",
    "            actions = actor(torch.cat([canvas, patch_img, stepnum, coord], 1))\n",
    "            canvas, res = decode(actions, canvas)\n",
    "            print('divided canvas step {}, L2Loss = {}'.format(i, ((canvas - patch_img) ** 2).mean()))\n",
    "            for j in range(5):\n",
    "                save_img(res[j], args.imgid, True)\n",
    "                args.imgid += 1\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_pytorch_p36)",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
